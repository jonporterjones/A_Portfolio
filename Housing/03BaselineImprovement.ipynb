{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Improvement\n",
    "\n",
    "This notebook seeks to improve upone the learned baseline from 02RegressionBaseline.\n",
    "\n",
    "We will explore options such as:\n",
    "\n",
    "* Removing features that are either non-linear or don't aid in prediction\n",
    "* Different scaling techniques\n",
    "* Other learning algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RESULT\n",
    "\n",
    "The random forest model beats our learned baseline by a substantial margin.  This model then becomes the new baseline to measure against.  \n",
    "These notebooks are meant to demonstrate how an ML project is an iterative process of continuous improvement.  The goal here is not an exhaustive analysis of the best possible model for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a random state for reproducible results\n",
    "x_train, x_test, y_train, y_test = train_test_split(housing.data,\n",
    "                                                    housing.target,\n",
    "                                                    test_size=0.1,\n",
    "                                                    random_state=66)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove non-linear features\n",
    "\n",
    "We suspect that the latitude/longitude features are non-linear and don't help our model learn.  Lets remove it and determine if it helps our fit or allow the model to find value in other parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train[:,0:6]\n",
    "x_test = x_test[:,0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(linear_model.LinearRegression(), x_train, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Scores (training data): [0.52686209 0.53295152 0.53429725 0.53464017 0.5338919 ]\n",
      "Average of all CV scores (training data): 0.5325285837990277\n"
     ]
    }
   ],
   "source": [
    "print(f'Cross Validation Scores (training data): {scores}')\n",
    "print(f'Average of all CV scores (training data): {scores.mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now fit the model on all train data\n",
    "model = linear_model.LinearRegression().fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict and score the test set to report our baseline performance.\n",
    "y_pred = model.predict(x_test)\n",
    "test_r2 = r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline regression using linear regression on test data : 0.563\n"
     ]
    }
   ],
   "source": [
    "print(f\"Baseline regression using linear regression on test data : {test_r2:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that latitude and longitude do - in this case - help our model learn.  \n",
    "This kind of goes against intuition but we'll continue to include it as it does improve the result.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put latitude and longitude back\n",
    "# use a random state for reproducible results\n",
    "x_train, x_test, y_train, y_test = train_test_split(housing.data,\n",
    "                                                    housing.target,\n",
    "                                                    test_size=0.1,\n",
    "                                                    random_state=66)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other models\n",
    "\n",
    "It would make sense to explore both linear and non-linear models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear \n",
    "\n",
    "From sklearns \"choosing the right estimator\" documentation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regresssion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(linear_model.Ridge(alpha=0.5), x_train, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Scores (training data): [0.60400196 0.59333461 0.59603562 0.598151   0.60854108]\n",
      "Average of all CV scores (training data): 0.6000128537068031\n"
     ]
    }
   ],
   "source": [
    "print(f'Cross Validation Scores (training data): {scores}')\n",
    "print(f'Average of all CV scores (training data): {scores.mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It performs almost identical, probably not necessary to check further.\n",
    "We could perform a grid search over the alpha parameter but some simple experimation shows that is not likely to be helpful.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-linear models\n",
    "\n",
    "Although this dataset seems to lend itself to linear models, we should take some time to explore both linear and non-linear models.\n",
    "\n",
    "The sklearn documentation sugggests Support Vector Regression (SVR)\n",
    "Lets quickly evaluate SVR\n",
    "\n",
    "Also will perform an evaluation of a Random Forest.  Random forest is often a good starting point to use in a non-linear setting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(svm.SVR(), x_train, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Scores (training data): [-0.03746847 -0.02152099 -0.03421931 -0.02271538 -0.01690274]\n",
      "Average of all CV scores (training data): -0.026565379387379462\n"
     ]
    }
   ],
   "source": [
    "print(f'Cross Validation Scores (training data): {scores}')\n",
    "print(f'Average of all CV scores (training data): {scores.mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model does objectively worse than even a naive baseline so this is not likely to be of benefit.  Doubtful that a grid search over the default parameters would improve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Froest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(RandomForestRegressor(), x_train, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Scores (training data): [0.79647755 0.81136297 0.80457527 0.7966518  0.80779239]\n",
      "Average of all CV scores (training data): 0.8033719965204252\n"
     ]
    }
   ],
   "source": [
    "print(f'Cross Validation Scores (training data): {scores}')\n",
    "print(f'Average of all CV scores (training data): {scores.mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random forest regressor beats our previous baseline.  \n",
    "\n",
    "Predict and score the test set to report our baseline performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor().fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict and score the test set to report our baseline performance.\n",
    "y_pred = model.predict(x_test)\n",
    "test_r2 = r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest regression on test data : 0.836\n"
     ]
    }
   ],
   "source": [
    "print(f\"Random Forest regression on test data : {test_r2:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling techniques\n",
    "\n",
    "We know from Exploration that some of the input features are not clean, they contain outliers, or they have been capped at a certain value.  Experimenting with different types of scaling in sklearn will allow us to explore if this approach improves upon our learned baseline.\n",
    "\n",
    "Note that a Random Forest model is not sensitive to standardized data so these techniques won't be applied to the current \"winning\" model.  We'll apply these techniques to the standard linear model from earlier as they will often perform better on standardized data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline with scaling and the model\n",
    "pipeline = Pipeline([('scaler', preprocessing.RobustScaler()), ('linear_regression', linear_model.LinearRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform cross-validation\n",
    "scores = cross_val_score(pipeline, x_train, y_train, cv=5)  # cv is the number of folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average of all CV scores: 0.6000078375660192\n"
     ]
    }
   ],
   "source": [
    "print(f'Average of all CV scores: {scores.mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance stays constand with scaled data indicating that the model did not really benefit from standardized data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "housing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
